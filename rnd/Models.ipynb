{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "142a4f0b-49a4-4505-b6b6-4e75bccb115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4042372-231d-433d-bc9a-b6f31e24f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('images_train.npy')\n",
    "X_test = np.load('images_test.npy')\n",
    "y_train = np.load('labels_train.npy')\n",
    "y_test = np.load('labels_test.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fc695bd-a9b4-4882-a241-b2fca71e6132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(images, labels):\n",
    "    images = torch.tensor(images, dtype=torch.float32).permute(0, 3, 1, 2)  \n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    return images, labels\n",
    "\n",
    "X_train, y_train = preprocess(X_train, y_train)\n",
    "X_test, y_test = preprocess(X_test, y_test)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13388bcd-7cf6-4afb-85be-b71cb80aae2c",
   "metadata": {},
   "source": [
    "# ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f56da2fc-47b0-4fe2-a6d8-13659f6aba4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTSdpaAttention(\n",
       "            (attention): ViTSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=y_train.shape[1], problem_type='multi_label_classification')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f2165e5-6925-44f6-9a23-342f1c9e81b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7189c7fb-8048-4468-83d6-0260df02d1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2404\n",
      "Epoch 2, Loss: 0.1167\n",
      "Epoch 3, Loss: 0.0715\n",
      "Epoch 4, Loss: 0.0411\n",
      "Epoch 5, Loss: 0.0245\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        inputs, targets = batch\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).logits\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b39b8fb-7bac-48e7-a339-f51c2421a07e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89       570\n",
      "           1       0.96      0.91      0.93      2366\n",
      "           2       0.91      0.82      0.86       318\n",
      "           3       0.90      0.86      0.88       273\n",
      "           4       0.93      0.93      0.93      3099\n",
      "           5       0.71      0.22      0.34       191\n",
      "           6       0.91      0.80      0.85      1060\n",
      "           7       0.89      0.87      0.88      1315\n",
      "           8       0.58      0.54      0.56       452\n",
      "           9       0.91      0.79      0.84      1833\n",
      "          10       0.93      0.84      0.88       558\n",
      "          11       0.82      0.85      0.83        68\n",
      "          12       0.81      0.64      0.71       236\n",
      "          13       0.72      0.76      0.74        82\n",
      "          14       0.97      0.97      0.97       667\n",
      "\n",
      "   micro avg       0.91      0.85      0.88     13088\n",
      "   macro avg       0.86      0.78      0.81     13088\n",
      "weighted avg       0.91      0.85      0.88     13088\n",
      " samples avg       0.83      0.80      0.81     13088\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arhipov.danil7/neew-env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/arhipov.danil7/neew-env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/arhipov.danil7/neew-env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "preds, true_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs).logits.cpu().numpy()\n",
    "        preds.append(outputs)\n",
    "        true_labels.append(targets.numpy())\n",
    "\n",
    "y_pred = np.vstack(preds) > 0.5  \n",
    "y_true = np.vstack(true_labels)\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=[str(i) for i in range(y_train.shape[1])]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b17427b-ae2e-4457-999e-5271aaab2245",
   "metadata": {},
   "source": [
    "# resnet Ð¸ effnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22a8ecf6-2786-4295-9653-e626828c7d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name, num_classes):\n",
    "    if model_name == \"resnet\":\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)  # ÐÐ·Ð¼ÐµÐ½ÑÐµÐ¼ Ð²ÑÑÐ¾Ð´Ð½Ð¾Ð¹ ÑÐ»Ð¾Ð¹\n",
    "    elif model_name == \"efficientnet\":\n",
    "        model = models.efficientnet_b3(pretrained=True)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)  # ÐÐ·Ð¼ÐµÐ½ÑÐµÐ¼ Ð²ÑÑÐ¾Ð´Ð½Ð¾Ð¹ ÑÐ»Ð¾Ð¹\n",
    "    else:\n",
    "        raise ValueError(\"'resnet' Ð¸Ð»Ð¸ 'efficientnet'\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb7c842c-fcb6-49d8-8de5-427883573dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arhipov.danil7/neew-env/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/arhipov.danil7/neew-env/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"efficientnet\"  \n",
    "model = get_model(model_name, y_train.shape[1])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42c8d774-ff0f-4209-9b6e-c4b8be182fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2617\n",
      "Epoch 2, Loss: 0.1575\n",
      "Epoch 3, Loss: 0.1206\n",
      "Epoch 4, Loss: 0.0938\n",
      "Epoch 5, Loss: 0.0737\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61d67802-0f33-4861-b674-e6c39434c414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       570\n",
      "           1       0.95      0.94      0.95      2366\n",
      "           2       0.88      0.78      0.83       318\n",
      "           3       0.91      0.84      0.87       273\n",
      "           4       0.92      0.94      0.93      3099\n",
      "           5       0.67      0.09      0.17       191\n",
      "           6       0.92      0.85      0.88      1060\n",
      "           7       0.90      0.87      0.89      1315\n",
      "           8       0.63      0.42      0.51       452\n",
      "           9       0.88      0.82      0.85      1833\n",
      "          10       0.89      0.91      0.90       558\n",
      "          11       0.78      0.82      0.80        68\n",
      "          12       0.77      0.74      0.75       236\n",
      "          13       0.72      0.72      0.72        82\n",
      "          14       0.98      0.98      0.98       667\n",
      "\n",
      "   micro avg       0.91      0.87      0.89     13088\n",
      "   macro avg       0.85      0.77      0.79     13088\n",
      "weighted avg       0.90      0.87      0.88     13088\n",
      " samples avg       0.85      0.82      0.83     13088\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arhipov.danil7/neew-env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/arhipov.danil7/neew-env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/arhipov.danil7/neew-env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "preds, true_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs).cpu().numpy()\n",
    "        preds.append(outputs)\n",
    "        true_labels.append(targets.numpy())\n",
    "\n",
    "y_pred = np.vstack(preds) > 0.5  \n",
    "y_true = np.vstack(true_labels)\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=[str(i) for i in range(y_train.shape[1])]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddcf245e-9d76-4799-97e4-e1933a3d2d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arhipov.danil7/neew-env/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/arhipov.danil7/neew-env/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1897\n",
      "Epoch 2, Loss: 0.1098\n",
      "Epoch 3, Loss: 0.0687\n",
      "Epoch 4, Loss: 0.0441\n",
      "Epoch 5, Loss: 0.0297\n"
     ]
    }
   ],
   "source": [
    "model_name = \"resnet\"  \n",
    "model = get_model(model_name, y_train.shape[1])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "epochs = 5\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7212d77-042e-4fe6-8dcf-2056ea92c1f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       570\n",
      "           1       0.93      0.96      0.95      2366\n",
      "           2       0.92      0.80      0.85       318\n",
      "           3       0.86      0.90      0.88       273\n",
      "           4       0.92      0.96      0.94      3099\n",
      "           5       0.78      0.28      0.41       191\n",
      "           6       0.89      0.88      0.89      1060\n",
      "           7       0.88      0.89      0.89      1315\n",
      "           8       0.57      0.44      0.50       452\n",
      "           9       0.86      0.87      0.86      1833\n",
      "          10       0.92      0.89      0.91       558\n",
      "          11       0.86      0.65      0.74        68\n",
      "          12       0.81      0.67      0.73       236\n",
      "          13       0.82      0.65      0.72        82\n",
      "          14       0.98      0.97      0.98       667\n",
      "\n",
      "   micro avg       0.90      0.89      0.89     13088\n",
      "   macro avg       0.86      0.78      0.81     13088\n",
      "weighted avg       0.89      0.89      0.89     13088\n",
      " samples avg       0.84      0.83      0.83     13088\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arhipov.danil7/neew-env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/arhipov.danil7/neew-env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/arhipov.danil7/neew-env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "preds, true_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs).cpu().numpy()\n",
    "        preds.append(outputs)\n",
    "        true_labels.append(targets.numpy())\n",
    "\n",
    "y_pred = np.vstack(preds) > 0.5 \n",
    "y_true = np.vstack(true_labels)\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=[str(i) for i in range(y_train.shape[1])]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8811c97-f9f2-40fc-b5c1-740e25029278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee41b8-bf96-4a47-b0b2-117c7a0a6e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545c06e8-4ba8-46b7-8808-2a4ddb8e66ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee8b025-9b47-4cf7-800b-beb63c31af7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998c0057-334d-43ee-93f0-b387ad36d54b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "danil",
   "language": "python",
   "name": "neew-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
